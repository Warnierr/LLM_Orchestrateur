# ü§ñ Guide d'Utilisation de Nina v0.2.0

## üåü D√©marrage Rapide

### Installation
```bash
pip install -e .
```

### Premier test
```bash
python nina.py --test
```

### Lancement de l'interface
```bash
python nina.py
```

## üí¨ Interface CLI

### Commandes disponibles
- **Questions naturelles** : Tapez directement votre question
- `/help` : Affiche l'aide
- `/stats` : Statistiques de la session
- `/reset` : Nouvelle session
- `/exit` : Quitter

### Exemples de questions
- "Quelles sont les derni√®res actualit√©s en IA ?"
- "Analyse-moi les tendances du machine learning"
- "Cr√©e un plan d'apprentissage pour le deep learning"
- "Recherche des informations sur les transformers"

## üéõÔ∏è Options CLI

### Test et diagnostic
```bash
python nina.py --test        # Test complet
python nina.py --version     # Informations syst√®me
```

### Questions directes
```bash
python nina.py --query "Votre question ici"
```

### Interface web (en d√©veloppement)
```bash
python nina.py --web
```

## üé¨ D√©monstration

### Lancer la d√©mo interactive
```bash
python demo.py
```

Cette d√©monstration vous montre :
- Collecte et analyse web
- R√©cup√©ration d'actualit√©s
- Analyse et recommandations
- Planification de t√¢ches

## ‚öôÔ∏è Configuration

### Variables d'environnement (.env)
```bash
# LLM Configuration
OPENAI_API_BASE=http://localhost:8080/v1
OPENAI_API_KEY=your_key_here
OPENAI_MODEL=mistral-7b

# Services externes
NEWSAPI_KEY=your_newsapi_key

# Configuration Nina
LOG_LEVEL=INFO
NINA_DATA_DIR=./data
MAX_SEARCH_RESULTS=10
```

### Configuration LLM Local

#### Avec LocalAI
```bash
# Installation LocalAI
curl https://localai.io/install.sh | sh

# Lancement
local-ai --models-path ./models
```

#### Avec Ollama
```bash
# Installation Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# T√©l√©chargement d'un mod√®le
ollama pull mistral:7b

# Lancement du serveur
ollama serve
```

## üß† Agents de Nina

### Agent Chercheur
- **Fonction** : Collecte de donn√©es web
- **Sources** : DuckDuckGo, APIs
- **Formats** : HTML, JSON, texte

### Agent Analyste
- **Fonction** : Analyse des donn√©es collect√©es
- **M√©thodes** : Extraction d'insights, statistiques
- **Sortie** : Rapports structur√©s

### Agent News
- **Fonction** : Actualit√©s sp√©cialis√©es IA
- **Sources** : NewsAPI.org, DuckDuckGo
- **Fallback** : Scraping automatique

### Agent Planificateur
- **Fonction** : Gestion de t√¢ches et objectifs
- **Capacit√©s** : Priorisation, √©ch√©ances
- **Int√©gration** : Calendrier, notifications

### Agent R√©dacteur
- **Fonction** : G√©n√©ration de rapports
- **Formats** : Markdown, texte structur√©
- **LLM** : Support LocalAI/Ollama/OpenAI

### Agent Apprentissage
- **Fonction** : Am√©lioration continue
- **M√©thodes** : M√©moire vectorielle, recommandations
- **Persistance** : Base Qdrant

## üîç Fonctionnalit√©s Avanc√©es

### Recherche S√©mantique (RAG)
- Base vectorielle Qdrant in-memory
- Embeddings d√©terministes
- Recherche par similarit√©
- M√©moire temporelle

### Syst√®me de M√©moire
- **M√©moire courte** : Session en cours
- **M√©moire longue** : Base vectorielle persistante
- **Apprentissage** : Am√©lioration des recommandations

### Collecte Web Intelligente
- User-Agent personnalis√©
- Gestion des timeouts
- Fallback automatique
- Rate limiting respectueux

## üêõ D√©pannage

### Probl√®mes courants

#### Import Error
```bash
# R√©installer le package
pip uninstall nina_project
pip install -e .
```

#### Tests qui √©chouent
```bash
# V√©rifier les d√©pendances
pip install -r requirements.txt

# Lancer les tests individuellement
python -m pytest tests/test_orchestrator.py -v
```

#### Erreur de connexion LLM
- V√©rifiez que LocalAI/Ollama fonctionne
- Configurez `OPENAI_API_BASE` correctement
- Testez avec `curl http://localhost:8080/v1/models`

#### Pas de r√©sultats web
- V√©rifiez votre connexion internet
- DuckDuckGo peut parfois bloquer les bots
- Ajoutez des d√©lais entre les requ√™tes

### Logs et Debug
```bash
# Mode debug
DEBUG=true python nina.py

# Logs d√©taill√©s
LOG_LEVEL=DEBUG python nina.py
```

## üìà M√©triques et Monitoring

### Statistiques de session
- Utilisez `/stats` dans l'interface CLI
- Historique des questions/r√©ponses
- Temps de traitement
- Agents utilis√©s

### Performance
- Temps de r√©ponse typique : 3-8 secondes
- Collecte web : 1-3 secondes
- Analyse : 0.5-1 seconde
- G√©n√©ration rapport : 1-2 secondes

## üîÆ Prochaines Fonctionnalit√©s

### Phase 2 (En d√©veloppement)
- Agent Nina principal autonome
- Syst√®me de d√©cision intelligent
- M√©moire utilisateur personnalis√©e
- Reasoning chain explicite

### Phase 3 (Planifi√©)
- Interface web Streamlit
- API REST compl√®te
- Int√©grations externes (Slack, Discord)
- Base de donn√©es relationnelle

### Phase 4 (Vision)
- Application mobile
- Extension navigateur
- Plugins et connecteurs
- Mode vocal

## üí° Conseils d'Utilisation

### Questions efficaces
- Soyez sp√©cifique : "Analyse les tendances IA en 2024" plut√¥t que "Parle-moi d'IA"
- Mentionnez le contexte : "Pour un d√©butant en ML" ou "Niveau avanc√©"
- Demandez des formats pr√©cis : "Fais un plan √©tape par √©tape"

### Optimisation des performances
- Laissez Nina apprendre : plus vous l'utilisez, meilleures sont ses recommandations
- Utilisez `/reset` pour des nouveaux sujets non li√©s
- Configurez un LLM local pour de meilleures r√©ponses

### Utilisation professionnelle
- Configurez vos propres APIs (NewsAPI, etc.)
- Personnalisez les prompts dans `configs/`
- Int√©grez dans vos CI/CD pour l'automatisation

## ü§ù Support et Contribution

### Support
- Documentation : Ce guide
- Issues : GitHub Issues
- Tests : `python nina.py --test`

### Contribution
- Code : Pull requests bienvenues
- Documentation : Am√©liorations sugg√©r√©es
- Tests : Nouveaux cas de test
- Id√©es : Discussions GitHub

---

**Nina v0.2.0** - Assistant IA Intelligent & Autonome  
*D√©velopp√© avec ‚ù§Ô∏è pour la communaut√© IA francophone* 